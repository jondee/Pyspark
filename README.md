# Pyspark

Description about a project .

Files are retreived from MapR cluster and then processed by pySpark into an Enterprise Data-Warehouse for reporting and Analytics.

#get gzip file from cluster 

#Create function that will give timestamp list 

# Use Data Frame as a placeholder for some of the resultsets

# Use spark_Sql to apply Business logic and python

# Write Data Frame into  DB (Oracle Table)
